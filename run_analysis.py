# -*- coding: utf-8 -*-
"""
å­¸æ¥­å£“åŠ›èˆ‡æ†‚é¬±é¢¨éšªç›¸é—œæ€§åˆ†æä¸»æ§ç¨‹å¼

æ­¤ç¨‹å¼æ•´åˆæ‰€æœ‰åˆ†ææµç¨‹ï¼Œå¾è³‡æ–™å‰è™•ç†ã€æ¨¡å‹è¨“ç·´åˆ°è¦–è¦ºåŒ–ï¼Œ
ä¸¦æ”¯æ´è³‡æ–™åŒ¯å‡ºè‡³ MySQL ä»¥ä¾› Grafana è¦–è¦ºåŒ–ä½¿ç”¨ã€‚

ç”¨æ³•ï¼š
    python run_analysis.py [--to-mysql]

åƒæ•¸ï¼š
    --to-mysql: æ˜¯å¦åŒ¯å‡ºè³‡æ–™è‡³ MySQLï¼Œé è¨­ç‚ºå¦
"""

import os
import sys
import argparse
import warnings
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.font_manager import FontProperties
import matplotlib.font_manager as fm
from scipy.stats import chi2_contingency
import time
from tqdm import tqdm

# è¼‰å…¥è‡ªå®šç¾©æ¨¡çµ„
from src.preprocess import preprocess
from src.plot_utils import (
    setup_chinese_font,
    plot_combined_depression_charts,
    plot_confusion_matrix,
    plot_feature_importance_bar,
    plot_roc_curves
)
from src.model_utils import train_and_evaluate
from src.db_utils import export_to_mysql, test_connection, create_schema
from src.font_loader import download_font_if_not_exist

# å¿½ç•¥ä¸å¿…è¦çš„è­¦å‘Š
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=RuntimeWarning)
warnings.filterwarnings(
    "ignore",
    message="Glyph .* missing from font\\(s\\) DejaVu Sans\\.",
    category=UserWarning,
    module="seaborn.utils"
)

class AnalysisProgressTracker:
    """çµ±ä¸€çš„åˆ†æé€²åº¦è¿½è¹¤å™¨"""
    
    def __init__(self, export_to_mysql=False):
        # æ ¹æ“šæ˜¯å¦åŒ¯å‡ºMySQLæ±ºå®šç¸½æ­¥é©Ÿæ•¸
        self.total_steps = 5 if export_to_mysql else 4
        self.current_step = 0
        self.pbar = None
        
        # æ­¥é©Ÿå®šç¾©
        self.steps = [
            ("ğŸ”§ ç’°å¢ƒè¨­å®š", "è¨­å®šå­—å‹èˆ‡åŸ·è¡Œç’°å¢ƒ"),
            ("ğŸ“Š è³‡æ–™é è™•ç†", "è¼‰å…¥èˆ‡æ¸…ç†è³‡æ–™"),
            ("ğŸ“ˆ çµ±è¨ˆåˆ†æ", "è¨ˆç®—ç›¸é—œæ€§èˆ‡çµ±è¨ˆæª¢å®š"),
            ("ğŸ¤– æ¨¡å‹è¨“ç·´", "æ©Ÿå™¨å­¸ç¿’æ¨¡å‹è¨“ç·´èˆ‡è©•ä¼°")
        ]
        
        if export_to_mysql:
            self.steps.append(("ğŸ—„ï¸ è³‡æ–™åŒ¯å‡º", "åŒ¯å‡ºè³‡æ–™è‡³MySQLè³‡æ–™åº«"))
    
    def start(self):
        """é–‹å§‹é€²åº¦è¿½è¹¤"""
        print("ğŸš€ EduDepression å­¸æ¥­å£“åŠ›èˆ‡æ†‚é¬±é¢¨éšªåˆ†æç³»çµ±")
        print("=" * 60)
        self.pbar = tqdm(
            total=100, 
            desc="æº–å‚™é–‹å§‹", 
            unit="%", 
            ncols=80,
            bar_format='{desc}: {percentage:3.0f}%|{bar}| {elapsed}<{remaining}'
        )
    
    def next_step(self, detail=""):
        """é€²å…¥ä¸‹ä¸€å€‹æ­¥é©Ÿ"""
        if self.pbar is None:
            return
            
        self.current_step += 1
        step_name, step_desc = self.steps[self.current_step - 1]
        
        # è¨ˆç®—é€²åº¦ç™¾åˆ†æ¯”
        progress = int((self.current_step - 1) / self.total_steps * 100)
        self.pbar.n = progress
        
        # æ›´æ–°æè¿°
        desc = f"{step_name}"
        if detail:
            desc += f" - {detail}"
        self.pbar.set_description(desc)
        self.pbar.refresh()
        
        # åœ¨æ§åˆ¶å°é¡¯ç¤ºæ­¥é©Ÿè³‡è¨Š
        print(f"\n{step_name}: {step_desc}")
        if detail:
            print(f"  â†’ {detail}")
    
    def update_detail(self, detail):
        """æ›´æ–°ç•¶å‰æ­¥é©Ÿçš„è©³ç´°è³‡è¨Š"""
        if self.pbar is None:
            return
            
        step_name, _ = self.steps[self.current_step - 1]
        desc = f"{step_name} - {detail}"
        self.pbar.set_description(desc)
        self.pbar.refresh()
    
    def finish_step(self):
        """å®Œæˆç•¶å‰æ­¥é©Ÿ"""
        if self.pbar is None:
            return
            
        # æ›´æ–°åˆ°ä¸‹ä¸€å€‹æ­¥é©Ÿçš„èµ·å§‹é»
        progress = int(self.current_step / self.total_steps * 100)
        self.pbar.n = progress
        self.pbar.refresh()
    
    def complete(self):
        """å®Œæˆæ‰€æœ‰åˆ†æ"""
        if self.pbar is None:
            return
            
        self.pbar.n = 100
        self.pbar.set_description("âœ… åˆ†æå®Œæˆ")
        self.pbar.refresh()
        self.pbar.close()

def setup_environment(progress_tracker):
    """
    è¨­å®šåŸ·è¡Œç’°å¢ƒï¼ŒåŒ…å«å­—å‹è¨­å®šèˆ‡è­¦å‘Šéæ¿¾ç­‰

    Args:
        progress_tracker: é€²åº¦è¿½è¹¤å™¨
        
    Returns:
        matplotlib.font_manager.FontProperties: ä¸­æ–‡å­—å‹å±¬æ€§ç‰©ä»¶
    """
    progress_tracker.next_step("ä¸‹è¼‰èˆ‡è¨­å®šä¸­æ–‡å­—å‹")
    
    # ä¸‹è¼‰å­—å‹
    progress_tracker.update_detail("ä¸‹è¼‰ä¸­æ–‡å­—å‹æª”æ¡ˆ")
    font_path = download_font_if_not_exist()
    
    # è¼‰å…¥å­—å‹
    progress_tracker.update_detail("è¼‰å…¥å­—å‹è‡³matplotlib")
    fm.fontManager.addfont(font_path)
    
    # è¨­å®š matplotlib
    progress_tracker.update_detail("è¨­å®šåœ–è¡¨é¡¯ç¤ºåƒæ•¸")
    plt.rcParams['font.family'] = 'Noto Sans CJK JP'
    plt.rcParams['axes.unicode_minus'] = False
    
    progress_tracker.finish_step()
    return FontProperties(fname=font_path)

def parse_args():
    """
    è§£æå‘½ä»¤åˆ—åƒæ•¸

    Returns:
        argparse.Namespace: è§£æå¾Œçš„åƒæ•¸ç‰©ä»¶
    """
    parser = argparse.ArgumentParser(description='å­¸æ¥­å£“åŠ›èˆ‡æ†‚é¬±é¢¨éšªç›¸é—œæ€§åˆ†æ')
    parser.add_argument('--to-mysql', action='store_true', 
                       help='æ˜¯å¦åŒ¯å‡ºè³‡æ–™è‡³ MySQLï¼Œé è¨­ç‚ºå¦')
    parser.add_argument('--data-path', type=str, 
                       default='data/student_depression_dataset.csv',
                       help='è³‡æ–™é›†è·¯å¾‘')
    return parser.parse_args()

def run_data_preprocessing(args, progress_tracker):
    """
    åŸ·è¡Œè³‡æ–™é è™•ç†

    Args:
        args: å‘½ä»¤åˆ—åƒæ•¸
        progress_tracker: é€²åº¦è¿½è¹¤å™¨
        
    Returns:
        pandas.DataFrame: è™•ç†å¾Œçš„è³‡æ–™æ¡†
    """
    progress_tracker.next_step("è¼‰å…¥åŸå§‹è³‡æ–™é›†")
    
    try:
        progress_tracker.update_detail("è®€å–CSVæª”æ¡ˆ")
        df = preprocess(args.data_path)
        
        progress_tracker.update_detail(f"è³‡æ–™é è™•ç†å®Œæˆ ({len(df)} ç­†)")
        print(f"  è™•ç†å¾Œè³‡æ–™é›†å¤§å°: {df.shape}")
        
        progress_tracker.finish_step()
        return df
        
    except Exception as e:
        print(f"  âŒ è³‡æ–™è™•ç†å¤±æ•—: {e}")
        sys.exit(1)

def run_statistical_analysis(df, zh_font, progress_tracker):
    """
    åŸ·è¡Œçµ±è¨ˆåˆ†æ

    Args:
        df (pandas.DataFrame): è™•ç†å¾Œçš„è³‡æ–™æ¡†
        zh_font (matplotlib.font_manager.FontProperties): ä¸­æ–‡å­—å‹å±¬æ€§ç‰©ä»¶
        progress_tracker: é€²åº¦è¿½è¹¤å™¨
    """
    progress_tracker.next_step("è¨ˆç®—ç›¸é—œä¿‚æ•¸èˆ‡çµ±è¨ˆæª¢å®š")
    
    # è¨ˆç®—å­¸æ¥­å£“åŠ›èˆ‡æ†‚é¬±é¢¨éšªçš„ç›¸é—œä¿‚æ•¸
    progress_tracker.update_detail("è¨ˆç®—å£“åŠ›èˆ‡æ†‚é¬±çš„ç›¸é—œæ€§")
    ap_corr = df['Academic Pressure_Value'].corr(df['Depression'])
    print(f"  å­¸æ¥­å£“åŠ›èˆ‡æ†‚é¬±é¢¨éšªçš„ç›¸é—œä¿‚æ•¸: {ap_corr:.3f}")

    # åˆ†æå„å£“åŠ›çµ„çš„æ†‚é¬±æ¯”ä¾‹
    progress_tracker.update_detail("åˆ†æå„å£“åŠ›çµ„æ†‚é¬±æ¯”ä¾‹")
    ap_group = df.groupby('Academic Pressure_Category')[
        'Depression'].agg(['mean', 'count'])
    ap_group.columns = ['æ†‚é¬±æ¯”ä¾‹', 'æ¨£æœ¬æ•¸']
    print("\n  ä¸åŒå­¸æ¥­å£“åŠ›æ°´å¹³çš„æ†‚é¬±é¢¨éšª:")
    print(ap_group.to_string(index=True))
    
    # é¡¯ç¤ºå„å£“åŠ›çµ„è©³ç´°çµ±è¨ˆ
    for category in ['ä½å£“åŠ›', 'ä¸­å£“åŠ›', 'é«˜å£“åŠ›']:
        if category in df['Academic Pressure_Category'].values:
            subset = df[df['Academic Pressure_Category'] == category]
            depression_rate = subset['Depression'].mean()
            count = len(subset)
            print(f"    {category}: æ†‚é¬±æ¯”ä¾‹ = {depression_rate:.1%}, æ¨£æœ¬æ•¸ = {count}")
    
    # å‰µå»ºäº¤å‰åˆ—è¯è¡¨èˆ‡å¡æ–¹æª¢å®š
    progress_tracker.update_detail("åŸ·è¡Œå¡æ–¹ç¨ç«‹æ€§æª¢å®š")
    contingency_table = pd.crosstab(
        df['Academic Pressure_Category'],
        df['Depression']
    )
    print(f"\n  äº¤å‰åˆ—è¯è¡¨ï¼š")
    print(contingency_table.to_string())
    
    # åŸ·è¡Œå¡æ–¹æª¢å®š
    chi2, p_value, dof, expected = chi2_contingency(contingency_table)
    print(f"\n  å¡æ–¹ç¨ç«‹æ€§æª¢å®šçµæœ:")
    print(f"    å¡æ–¹å€¼: {chi2:.3f}, è‡ªç”±åº¦: {dof}, p-value: {p_value:.4f}")
    print(f"    çµè«–: {'å£“åŠ›ç­‰ç´šä¹‹é–“æ†‚é¬±é¢¨éšªæœ‰é¡¯è‘—å·®ç•°' if p_value < 0.05 else 'å£“åŠ›ç­‰ç´šä¹‹é–“æ†‚é¬±é¢¨éšªæ²’æœ‰é¡¯è‘—å·®ç•°'}")
    
    # ç¹ªè£½è¦–è¦ºåŒ–åœ–è¡¨
    progress_tracker.update_detail("ç”Ÿæˆçµ±è¨ˆè¦–è¦ºåŒ–åœ–è¡¨")
    plot_combined_depression_charts(df, zh_font)
    
    progress_tracker.finish_step()

def run_model_analysis(df, zh_font, progress_tracker):
    """
    åŸ·è¡Œæ¨¡å‹è¨“ç·´èˆ‡è©•ä¼°

    Args:
        df (pandas.DataFrame): è™•ç†å¾Œçš„è³‡æ–™æ¡†
        zh_font (matplotlib.font_manager.FontProperties): ä¸­æ–‡å­—å‹å±¬æ€§ç‰©ä»¶
        progress_tracker: é€²åº¦è¿½è¹¤å™¨
        
    Returns:
        dict: æ¨¡å‹è¨“ç·´èˆ‡è©•ä¼°çµæœ
    """
    progress_tracker.next_step("ç‰¹å¾µé¸æ“‡èˆ‡æ¨¡å‹è¨“ç·´")
    
    # é¸æ“‡ç‰¹å¾µ
    progress_tracker.update_detail("é¸æ“‡æ¨¡å‹ç‰¹å¾µè®Šæ•¸")
    features = [
        'Academic Pressure_Value', 'degree_ord4', 'Age', 
        'CGPA', 'Study Satisfaction'
    ]
    features.extend([col for col in df.columns if col.startswith('Gender_')])
    
    # è¨“ç·´èˆ‡è©•ä¼°æ¨¡å‹
    progress_tracker.update_detail("è¨“ç·´Logistic Regressionå’ŒRandom Forestæ¨¡å‹")
    print("\n====== é æ¸¬æ¨¡å‹å»ºç«‹èˆ‡è©•ä¼° ======")
    results = train_and_evaluate(df, features)

    # ç¹ªè£½æ¨¡å‹è©•ä¼°åœ–è¡¨
    progress_tracker.update_detail("ç”Ÿæˆæ¨¡å‹è©•ä¼°åœ–è¡¨")
    
    # æ··æ·†çŸ©é™£
    plot_confusion_matrix(
        results['lr_results']['confusion_matrix'], 
        zh_font, 
        'Logistic Regression æ··æ·†çŸ©é™£'
    )
    
    # ç‰¹å¾µé‡è¦æ€§åœ–è¡¨
    plot_feature_importance_bar(
        results['lr_importance'], 
        zh_font, 
        'Logistic Regression ç‰¹å¾µé‡è¦æ€§'
    )
    plot_feature_importance_bar(
        results['rf_importance'], 
        zh_font, 
        'Random Forest ç‰¹å¾µé‡è¦æ€§'
    )
    
    # ROC æ›²ç·š
    y_test = results['y_test']
    roc_data = [
    (y_test, results['lr_results']['y_proba'], 'Logistic Regression', results['lr_results']['auc']),
    (y_test, results['rf_results']['y_proba'], 'Random Forest',       results['rf_results']['auc'])
    ]
    plot_roc_curves(roc_data, zh_font)
    
    progress_tracker.finish_step()
    
    # è¼¸å‡ºç ”ç©¶çµè«–
    print("\n====== ç ”ç©¶çµè«–èˆ‡å»ºè­° ======")
    print(f"\n1. å­¸æ¥­å£“åŠ›èˆ‡æ†‚é¬±é¢¨éšªçš„ç›¸é—œä¿‚æ•¸ç‚º {df['Academic Pressure_Value'].corr(df['Depression']):.3f}")
    
    print(f"\n2. å­¸æ¥­å£“åŠ›åœ¨é æ¸¬æ†‚é¬±é¢¨éšªçš„ç‰¹å¾µä¸­:")
    print(f"   - åœ¨Logistic Regressionæ¨¡å‹ä¸­æ’åç¬¬{results['ap_lr_rank']}ä½")
    print(f"   - åœ¨éš¨æ©Ÿæ£®æ—æ¨¡å‹ä¸­æ’åç¬¬{results['ap_rf_rank']}ä½")
    
    print("\n3. ä¸åŒå­¸æ¥­å£“åŠ›ç´šåˆ¥çš„æ†‚é¬±é¢¨éšª:")
    for level, row in df.groupby('Academic Pressure_Category')['Depression'].agg(['mean', 'count']).iterrows():
        print(f"   - {level}: {row['mean']:.2%} (æ¨£æœ¬æ•¸: {row['count']})")
    
    print("\n4. ç ”ç©¶å»ºè­°:")
    print("   - æ ¹æ“šåˆ†æçµæœï¼Œæ‡‰è©²æä¾›æ›´å¤šçš„å¿ƒç†å¥åº·è³‡æºçµ¦é«˜å­¸æ¥­å£“åŠ›å­¸ç”Ÿ")
    print("   - å­¸æ ¡å¯ä»¥ç™¼å±•å£“åŠ›ç®¡ç†åŸ¹è¨“èª²ç¨‹ï¼Œç‰¹åˆ¥é‡å°é«˜é¢¨éšªå­¸ç”Ÿç¾¤é«”")
    print("   - é€²ä¸€æ­¥ç ”ç©¶å¯ä»¥æ¢ç´¢å­¸æ¥­å£“åŠ›èˆ‡å…¶ä»–å› ç´ ï¼ˆå¦‚ç¤¾äº¤æ”¯æŒã€ç¡çœ è³ªé‡ï¼‰çš„äº¤äº’ä½œç”¨")
    
    return results

def export_data_to_mysql(df, progress_tracker):
    """
    å°‡è³‡æ–™åŒ¯å‡ºè‡³ MySQL è³‡æ–™åº«

    Args:
        df (pandas.DataFrame): è™•ç†å¾Œçš„è³‡æ–™æ¡†
        progress_tracker: é€²åº¦è¿½è¹¤å™¨
        
    Returns:
        bool: åŒ¯å‡ºæ˜¯å¦æˆåŠŸ
    """
    progress_tracker.next_step("é€£æ¥MySQLä¸¦åŒ¯å‡ºè³‡æ–™")
    
    # æ¸¬è©¦è³‡æ–™åº«é€£æ¥
    progress_tracker.update_detail("æ¸¬è©¦MySQLè³‡æ–™åº«é€£æ¥")
    if not test_connection():
        print("  âŒ ç„¡æ³•é€£æ¥è‡³ MySQL è³‡æ–™åº«ï¼Œè«‹æª¢æŸ¥é€£æ¥è¨­å®š")
        return False
    
    # å»ºç«‹è³‡æ–™åº«çµæ§‹
    progress_tracker.update_detail("å»ºç«‹è³‡æ–™åº«è¡¨æ ¼çµæ§‹")
    sql_file_path = os.path.join(os.path.dirname(__file__), "db", "create_table.sql")
    if os.path.exists(sql_file_path):
        print("  å»ºç«‹è³‡æ–™åº«çµæ§‹...")
        create_schema(sql_file_path)
    
    # åŒ¯å‡ºè³‡æ–™
    progress_tracker.update_detail("åŸ·è¡Œè³‡æ–™åŒ¯å‡ºä½œæ¥­")
    print("  åŒ¯å‡ºè³‡æ–™è‡³ MySQL...")
    success = export_to_mysql(df, "student_depression")
    
    # å›å ±çµæœ
    if success:
        print("  âœ… è³‡æ–™æˆåŠŸåŒ¯å‡ºè‡³ MySQLï¼")
        print("  ğŸ’¡ æ‚¨ç¾åœ¨å¯ä»¥ä½¿ç”¨ Grafana é€£æ¥ MySQL é€²è¡Œè¦–è¦ºåŒ–")
    else:
        print("  âŒ è³‡æ–™åŒ¯å‡ºå¤±æ•—ï¼")
    
    progress_tracker.finish_step()
    return success

def main():
    """
    ä¸»ç¨‹å¼æµç¨‹
    """
    # è§£æå‘½ä»¤åˆ—åƒæ•¸
    args = parse_args()
    
    # åˆå§‹åŒ–é€²åº¦è¿½è¹¤å™¨
    progress_tracker = AnalysisProgressTracker(export_to_mysql=args.to_mysql)
    progress_tracker.start()
    
    try:
        # è¨­å®šç’°å¢ƒèˆ‡å­—å‹
        zh_font = setup_environment(progress_tracker)
        
        # è®€å–ä¸¦å‰è™•ç†è³‡æ–™
        df = run_data_preprocessing(args, progress_tracker)
        
        # åŸ·è¡Œçµ±è¨ˆåˆ†æ
        run_statistical_analysis(df, zh_font, progress_tracker)
        
        # åŸ·è¡Œæ¨¡å‹è¨“ç·´èˆ‡è©•ä¼°
        model_results = run_model_analysis(df, zh_font, progress_tracker)
        
        # åŒ¯å‡ºè³‡æ–™è‡³ MySQLï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if args.to_mysql:
            export_data_to_mysql(df, progress_tracker)
        else:
            print("\nğŸ’¡ è‹¥è¦åŒ¯å‡ºè³‡æ–™è‡³ MySQLï¼Œè«‹ä½¿ç”¨ --to-mysql åƒæ•¸")
        
        # å®Œæˆåˆ†æ
        progress_tracker.complete()
        print("\nğŸ‰ æ‰€æœ‰åˆ†æå·²æˆåŠŸå®Œæˆï¼")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ¶ä¸­æ–·äº†åˆ†æç¨‹åº")
        progress_tracker.complete()
        sys.exit(1)
    except Exception as e:
        print(f"\n\nâŒ åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        progress_tracker.complete()
        sys.exit(1)

# ç•¶ç›´æ¥åŸ·è¡Œæ­¤æ¨¡çµ„æ™‚
if __name__ == "__main__":
    # é˜²æ­¢ plt.show() é˜»å¡ç¨‹å¼åŸ·è¡Œ
    plt.ion()
    
    # åŸ·è¡Œä¸»ç¨‹å¼
    main()
    
    # ç­‰å¾…ä½¿ç”¨è€…æŒ‰éµçµæŸç¨‹å¼
    plt.ioff()
    input("\næŒ‰ä¸‹ Enter éµçµæŸç¨‹å¼...")
